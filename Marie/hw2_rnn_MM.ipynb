{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtcBjMq7YV3f"
      },
      "source": [
        "# Homework 2 - Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn-cOk1iZTtR"
      },
      "source": [
        "In this part of the homework we are going to work with Recurrent Neural Networks, in particular GRU. One of the greatest things that Recurrent Neural Networks can do when working with sequences is retaining data from several timesteps in the past. We are going to explore that property by constructing an 'echo' Recurrent Neural Network.\n",
        "\n",
        "The goal here is to make a model that given a sequence of letters or digits will output that same sequence, but with a certain delay. Let's say the input is a string 'abacaba', we want the model to not output anything for 3 steps (delay length), and then output the original string step by step, except the last 3 characters. So, target output is then 'XXXabac', where 'X' is empty output.\n",
        "\n",
        "This is similar to [this notebook](https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb) (which you should refer to when doing this assignment), except we're working not with a binary string, but with a sequence of integers between 0 and some N. In our case N is 26, which is the number of letters in the alphabet.\n",
        "\n",
        "A **synchronized many-to-many task** is a type of machine learning problem where the input and output sequences have different lengths and the sequences need to be aligned in time. In this type of task, a sequence of inputs is mapped to a sequence of outputs, where the number of inputs and outputs can be different for each time step (eg machine translation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npLlE973as6x"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Let's implement the dataset. In our case, the data is basically infinite, as we can always generate more examples on the fly, so don't need to load anything from disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mkEEMyvzIMRx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "import torch\n",
        "\n",
        "# Max value of the generated integer. 26 is chosen becuase it's\n",
        "# the number of letters in English alphabet.\n",
        "N = 26\n",
        "\n",
        "\n",
        "def idx_to_onehot(x, k=N+1):\n",
        "  \"\"\" Converts the generated integers to one-hot vectors \"\"\"\n",
        "  ones = torch.sparse.torch.eye(k) # creates a sparse identity matrix of size k\n",
        "  shape = x.shape\n",
        "  #  reshape the x tensor into a 1D tensor, where each element represents an index\n",
        "  #  pass to the index_select method of the identity matrix:\n",
        "  #  selects the corresponding row of the identity matrix for each index in the x tensor.\n",
        "  res = ones.index_select(0, x.view(-1).type(torch.int64))\n",
        "  return res.view(*shape, res.shape[-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kf9p9iASTngF",
        "outputId": "35bd7852-6d39-4672-e23c-395194b6914d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 27])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "x_out = idx_to_onehot(x = torch.tensor([1, 2]))\n",
        "print(x_out.shape)\n",
        "x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnIkK08RaHHK",
        "outputId": "e2453a52-3fcf-4556-a8aa-d6ef7b55da7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# can take advantage of the one-hot encoding\n",
        "# of the target and call argmax along its second dimension to create a tensor of shape\n",
        "# (batch_size) containing the index of the class label that was hot for each sequence.\n",
        "x_out.argmax(dim = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1ViWK4OpTl7-"
      },
      "outputs": [],
      "source": [
        "class EchoDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "  def __init__(self, delay=4, seq_length=15, size=1000):\n",
        "    self.delay = delay\n",
        "    self.seq_length = seq_length\n",
        "    self.size = size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __iter__(self):\n",
        "    \"\"\" Iterable dataset doesn't have to implement __getitem__.\n",
        "        Instead, we only need to implement __iter__ to return\n",
        "        an iterator (or generator).\n",
        "\n",
        "        The advantage of using __iter__ instead of __getitem__ is that\n",
        "        it provides a more flexible and memory-efficient way to access the data,\n",
        "        since it allows you to generate the samples on-the-fly\n",
        "        instead of loading them all into memory.\n",
        "        This can be especially useful when dealing with large datasets.\n",
        "    \"\"\"\n",
        "    for _ in range(self.size):\n",
        "      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n",
        "      result = torch.cat((torch.zeros(self.delay), seq[:self.seq_length - self.delay])).type(torch.int64)\n",
        "      yield seq, result\n",
        "\n",
        "DELAY = 4\n",
        "DATASET_SIZE = 200000\n",
        "ds = EchoDataset(delay=DELAY, size=DATASET_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-GtALrZhTSO",
        "outputId": "f42f9ad8-4af7-4b93-f017-5752852d6ab2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: tensor([13, 17, 12,  4, 20,  2, 19,  3,  4]) , label: tensor([ 0,  0,  0, 13, 17, 12,  4, 20,  2])\n",
            "Data: tensor([15,  4,  8, 19, 17,  1,  5, 25,  2]) , label: tensor([ 0,  0,  0, 15,  4,  8, 19, 17,  1])\n"
          ]
        }
      ],
      "source": [
        "ds_small = EchoDataset(delay=3, size=2, seq_length = 9)\n",
        "for data, label in ds_small:\n",
        "  print(\"Data:\", data, \", label:\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMYAHLgrTgL7",
        "outputId": "f11d926f-6557-4a63-c2cd-d54e3fd6ec66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxfAu4O1UfoQ",
        "outputId": "76abba85-01fc-4a01-92d4-8f204189df70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i: 0 Data: tensor([17, 14, 26, 17, 15, 26,  4, 21,  3]) , label: tensor([ 0,  0,  0, 17, 14, 26, 17, 15, 26])\n",
            "i: 1 Data: tensor([ 9, 26, 21, 20,  2, 19, 20, 25, 19]) , label: tensor([ 0,  0,  0,  9, 26, 21, 20,  2, 19])\n"
          ]
        }
      ],
      "source": [
        "for i, (data, label) in enumerate(ds_small):\n",
        "        print(\"i:\", i, \"Data:\", data, \", label:\", label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l0vlqRBfUoAV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNrZqYURcKSl"
      },
      "source": [
        "## Model\n",
        "\n",
        "Now, we want to implement the model. For our purposes, we want to use GRU. The architecture consists of GRU and a decoder. Decoder is responsible for decoding the GRU hidden state to yield a predicting for the next output. The parts you are responsible for filling with your code are marked with `TODO`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "OnZaRu8xVBnp"
      },
      "outputs": [],
      "source": [
        "def map_letters_to_numbers(input_string):\n",
        "  \"\"\"\n",
        "  In this function, the chr function is used to get the character\n",
        "  corresponding to a given ASCII code.\n",
        "  The ASCII code for a is 97, so adding 96 to a number gives us the ASCII code\n",
        "  for the corresponding letter.\n",
        "  \"\"\"\n",
        "  result = []\n",
        "  for char in input_string:\n",
        "    if char.isalpha():\n",
        "      char = char.lower()\n",
        "      result.append(ord(char) - 96)\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kYvCG53VIHs",
        "outputId": "d21a447d-dcd9-4f2c-d83c-7e863a64ebc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "map_letters_to_numbers('abcde')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H3cE8KTiVf1L"
      },
      "outputs": [],
      "source": [
        "def map_numbers_to_letters(input_numbers):\n",
        "    result = []\n",
        "    for num in input_numbers:\n",
        "        if 1 <= num <= 26:\n",
        "            result.append(chr(num + 96))\n",
        "    return ''.join(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AYymIq9VVgy9",
        "outputId": "7e9c2055-5b2e-4099-9b9b-514b38083355"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "map_numbers_to_letters([1, 2, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m77jq1e2pbbm"
      },
      "source": [
        "Things tried :\n",
        "* ReLU before linear layer (makes things worse)\n",
        "* two linear layers with ReLU in between (gets stuck on single number prediction) or sigmoid (correctly predicts first four 0s but doesn't learn beyond)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "nigN_o4Mb9Nx"
      },
      "outputs": [],
      "source": [
        "class GRUMemory(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, n_categories, middle_size = 128):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    self.linear_in = torch.nn.Linear(n_categories + 1, hidden_size)\n",
        "\n",
        "    self.gru = torch.nn.GRU(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True\n",
        "        )\n",
        "    # only use last time step as input for linear layer so only need hidden size as input\n",
        "    self.linear_out = torch.nn.Linear(hidden_size, n_categories + 1)\n",
        "\n",
        "  def forward(self, x, h):\n",
        "    # inputs: x - input tensor of shape (batch_size, seq_length, N+1)\n",
        "    # returns:\n",
        "    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n",
        "    x = self.linear_in(x)\n",
        "    x, h = self.gru(x)\n",
        "    x = self.linear_out(x)\n",
        "    # x = torch.softmax(x, dim = -1)\n",
        "    return x, h\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test_run(self, s):\n",
        "    # This function accepts one string s containing lowercase characters a-z.\n",
        "    # You need to map those characters to one-hot encodings,\n",
        "    # then get the result from your network, and then convert the output\n",
        "    # back to a string of the same length, with 0 mapped to ' ',\n",
        "    # and 1-26 mapped to a-z.\n",
        "\n",
        "    # function idx_to_onehot takes numerical indices\n",
        "    s = map_letters_to_numbers(s)\n",
        "    s_hot = idx_to_onehot(torch.tensor(s))\n",
        "\n",
        "    h = None\n",
        "    # model expects (batch, T, H_in)\n",
        "    s_hot = s_hot.unsqueeze(0)\n",
        "\n",
        "    logits, _ = self(s_hot, h = None)\n",
        "\n",
        "    ### model is going to return softmax scores :\n",
        "    ### get indices using argmax\n",
        "    output = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    ## convert back to strings\n",
        "    s_out = map_numbers_to_letters(output.squeeze().tolist())\n",
        "\n",
        "    return s_out\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ4G7Ne1V0Ok"
      },
      "source": [
        "The number of features in the hidden unit of a GRU is a design choice and can be different from the number of input features (n). It's common to use the same number of hidden units as input features, but this is not always the case. In general, the number of hidden units is a hyperparameter that can be tuned during the model training process. Another approach is to use rules of thumb based on the complexity of the data and task. For example, a simple rule of thumb is to choose the number of hidden units to be between the input and output size. However, this is just a rough guideline and the optimal number of hidden units can vary depending on the specific task and dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "xzmRA1qTbLbb"
      },
      "outputs": [],
      "source": [
        "model = GRUMemory(hidden_size = 64, n_categories = N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u74PDLaupbbn",
        "outputId": "c54973c3-66b2-43ba-bda5-5be6e2b66f1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_in.weight torch.Size([64, 27])\n",
            "linear_in.bias torch.Size([64])\n",
            "gru.weight_ih_l0 torch.Size([192, 64])\n",
            "gru.weight_hh_l0 torch.Size([192, 64])\n",
            "gru.bias_ih_l0 torch.Size([192])\n",
            "gru.bias_hh_l0 torch.Size([192])\n",
            "linear_out.weight torch.Size([27, 64])\n",
            "linear_out.bias torch.Size([27])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Z4uCPNTbpbbn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0NoCSJHi_CD-",
        "outputId": "a154e482-c93f-4969-e783-a542e038f385"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'zpppp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model.test_run(\"abcde\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd_6fw-qwlSd",
        "outputId": "0d647164-5800-4d45-e457-5a7dc51406a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GRUMemory(\n",
              "  (linear_in): Linear(in_features=27, out_features=64, bias=True)\n",
              "  (gru): GRU(64, 64, batch_first=True)\n",
              "  (linear_out): Linear(in_features=64, out_features=27, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FBLueLNGKr6m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7Wx9zLrUgXik"
      },
      "outputs": [],
      "source": [
        "# define training and testing data\n",
        "\n",
        "train_data = EchoDataset(delay=DELAY, size=DATASET_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qs2BYFdWpbbn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size = 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mQt2FB8Tpbbn",
        "outputId": "ccf025ea-2bea-41be-f67a-8c4f32a4e66b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "len(train_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "wN5HpSAnpbbo",
        "outputId": "322a12ac-87ea-4a4a-c0ed-213a2407fbe3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: torch.Size([50, 15])\n",
            "Label shape: torch.Size([50, 15])\n"
          ]
        }
      ],
      "source": [
        "for batch_idx in train_dataloader:\n",
        "    data, label = batch_idx\n",
        "    print(\"Data shape:\", data.shape)\n",
        "    print(\"Label shape:\", label.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "5maLvNlEb0Xp"
      },
      "outputs": [],
      "source": [
        "ds_test = EchoDataset(delay=3, size=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cX2vvSangKsg",
        "outputId": "05a095c1-5ebc-4de1-dd39-c00eb4ffc933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence shape torch.Size([15])\n",
            "label shape torch.Size([15])\n"
          ]
        }
      ],
      "source": [
        "for seq, lab in train_data:\n",
        "  print(\"Sequence shape\", seq.shape)\n",
        "  print(\"label shape\", lab.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxVbZcpRwOfz",
        "outputId": "fcc265ef-c634-4308-bf43-0a5baacd38e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xW05Ckz-9_u3",
        "outputId": "7f46b7b8-e17a-41c0-d995-dcbe839e64d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA\n",
            "tensor([15,  9,  5,  4, 15,  4, 18, 15, 16,  4,  9, 12, 13, 13,  1])\n",
            "LABEL\n",
            "tensor([ 0,  0,  0, 15,  9,  5,  4, 15,  4, 18, 15, 16,  4,  9, 12])\n"
          ]
        }
      ],
      "source": [
        "for batch in ds_test:\n",
        "  data, label = batch\n",
        "  print(\"DATA\")\n",
        "  print(data)\n",
        "  print(\"LABEL\")\n",
        "  print(label)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ziUq3Rdg-Thc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9whwmVu9OIx"
      },
      "source": [
        "## Training\n",
        "Below you need to implement the training of the model. We give you more freedom as for the implementation. The two limitations are that it has to execute within 10 minutes, and that error rate should be below 1%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lPkueQv1dI9H"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "# criterion = torch.nn.MultiLabelMarginLoss()\n",
        "# optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001) # works better than 0.1?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "zVaFYg0dVgr_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TySWwyVzRqmT"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    \"\"\"\n",
        "    copied from https://github.com/Atcold/pytorch-Deep-Learning/blob/master/09-echo_data.ipynb\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # New epoch --> fresh hidden state\n",
        "    hidden = None   # initialize hidden state with zeros\n",
        "    correct = 0\n",
        "\n",
        "    print_count = 0\n",
        "\n",
        "    n_samples = 0\n",
        "\n",
        "    for batch_idx in train_dataloader:\n",
        "    # for batch_idx in ds_test: # mini dataset for comp speed\n",
        "        data, target = batch_idx\n",
        "        optimizer.zero_grad()\n",
        "        # if hidden is not None: hidden.detach_()\n",
        "\n",
        "        # add dimension for batch -- don't need if use dataloader\n",
        "        # data = data.unsqueeze(0)\n",
        "\n",
        "        # Model works when sequence is one hot encoded\n",
        "        data = idx_to_onehot(data)\n",
        "        data = data.to(device)\n",
        "\n",
        "        target_OH = idx_to_onehot(target)\n",
        "        target_OH = target_OH.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "      # Do forward pass\n",
        "        logits, _ = model(data, h = None)\n",
        "\n",
        "        # cross entropy with logits\n",
        "        # TORCH.NN.FUNCTIONAL.CROSS_ENTROPY takes\n",
        "        # input : Predicted unnormalized logits\n",
        "        # target : Ground truth class INDICES\n",
        "\n",
        "#         if print_count < 2:\n",
        "#             print(\"One hot encoded data (input) shape:\", data.shape)\n",
        "#             print(\"Logit shape :\", logits.shape)\n",
        "#             print(\"Target shape:\", target.shape)\n",
        "#             print(\"Data shape \",  data.shape[0])\n",
        "#             print(\"OHE target shape:\", target_OH.shape)\n",
        "#             print(\"\")\n",
        "\n",
        "\n",
        "        # loss = criterion(logits.squeeze(), target) # RuntimeError: Expected target size [50, 27], got [50, 15]\n",
        "\n",
        "        loss = criterion(logits.reshape(-1, N+1), target.reshape(-1))\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # model returns softmax scores :\n",
        "        # get indices using argmax\n",
        "        pred = torch.argmax(logits, dim=-1).squeeze()\n",
        "\n",
        "        if (epoch == 2) | (epoch == 8):\n",
        "            print_count += 1\n",
        "            if (print_count) < 2:\n",
        "                print(\"PREDICTION:\")\n",
        "                print(pred)\n",
        "                print(\"TARGET:\")\n",
        "                print(target)\n",
        "                print(\"\")\n",
        "\n",
        "\n",
        "        correct += (pred == target).int().sum().item()/target.shape[1] # divide by sequence length here\n",
        "        n_samples += target.shape[0]\n",
        "\n",
        "    correct = correct/n_samples # will return number between 0 and 1\n",
        "\n",
        "    return correct, loss.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lUZkeRnVTNzG"
      },
      "outputs": [],
      "source": [
        "def test_model(model, sequence_length=15, D = 4):\n",
        "    \"\"\"\n",
        "    This is the test function that runs 100 different strings through your model,\n",
        "    and checks the error rate.\n",
        "    \"\"\"\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.to('cpu')\n",
        "\n",
        "\n",
        "    for i in range(1):\n",
        "        printer = 0\n",
        "\n",
        "        s = ''.join([random.choice(string.ascii_lowercase) for i in range(random.randint(15, 25))])\n",
        "        result = model.test_run(s)\n",
        "\n",
        "        # if printer < 1:\n",
        "        #   print(\"Label:\", s)\n",
        "        #   print(\"Label length:\", len(s))\n",
        "        #   print(\"Prediction:\", result)\n",
        "        #   print(\"Label length:\", len(result))\n",
        "        #   printer += 1\n",
        "\n",
        "        assert D > 0, 's[:-D] won\\'t work for D=0'\n",
        "\n",
        "        #for c1, c2 in zip(s[:-D], result[D:]):\n",
        "        for c1, c2 in zip(s[:-D], result): #### something wrong with the test run : it's not returning the full sequence length?\n",
        "            # print(\"c1:\", c1)\n",
        "            # print(\"c2:\", c2)\n",
        "            correct += int(c1 == c2)\n",
        "        total += len(s) - D\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "BbFvXRzWpbbs",
        "outputId": "b5eb6719-5557-414f-9277-e0b361b15d41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1/10, loss: 0.004, accuracy 87.0%\n",
            "PREDICTION:\n",
            "tensor([[ 0,  0,  0,  0, 10, 14,  8, 10,  9, 26,  1, 21, 11, 26, 15],\n",
            "        [ 0,  0,  0,  0, 24, 11,  9, 26, 24, 10,  6, 17, 19, 11, 15],\n",
            "        [ 0,  0,  0,  0, 18, 24, 12, 21, 20, 22,  8,  5,  6, 15,  7],\n",
            "        [ 0,  0,  0,  0,  3, 11, 23, 22,  4,  4,  5, 20,  5, 22, 20],\n",
            "        [ 0,  0,  0,  0,  1, 21, 13,  9,  6, 24,  4,  2, 11, 15, 22],\n",
            "        [ 0,  0,  0,  0, 19, 20, 21,  7, 10, 17,  5, 23,  5, 19, 12],\n",
            "        [ 0,  0,  0,  0, 19,  6, 24,  9,  4,  9, 20,  4, 12, 14, 10],\n",
            "        [ 0,  0,  0,  0,  3, 18, 18, 10,  3,  5, 11, 14, 18, 20, 17],\n",
            "        [ 0,  0,  0,  0,  1, 12, 18, 22, 21,  3, 20, 15,  7, 15, 18],\n",
            "        [ 0,  0,  0,  0, 23, 17, 18,  8,  3, 14, 18,  8, 15, 26,  6],\n",
            "        [ 0,  0,  0,  0, 24, 20, 22,  1, 16, 15,  3,  1, 16, 17,  4],\n",
            "        [ 0,  0,  0,  0, 16, 18, 21, 24, 19, 17, 14, 11, 21, 13, 16],\n",
            "        [ 0,  0,  0,  0, 16, 20, 23, 19, 24,  1,  3,  7, 20, 19, 13],\n",
            "        [ 0,  0,  0,  0, 10, 10, 22, 26, 17,  2, 10, 12, 23,  4,  6],\n",
            "        [ 0,  0,  0,  0, 19,  8, 26, 14, 24, 13, 17, 18, 24, 20,  6],\n",
            "        [ 0,  0,  0,  0, 23, 15, 26, 25,  9, 23,  5, 22, 13,  7, 20],\n",
            "        [ 0,  0,  0,  0, 23,  6, 15, 21, 17,  1,  8,  6, 20, 25, 22],\n",
            "        [ 0,  0,  0,  0, 22,  6,  1, 22, 24, 25, 11, 14,  9, 19, 21],\n",
            "        [ 0,  0,  0,  0, 17, 24, 19,  1,  6, 10, 23, 11,  2, 13,  7],\n",
            "        [ 0,  0,  0,  0,  5,  5, 23, 11, 17,  2,  3, 19, 22,  8, 14],\n",
            "        [ 0,  0,  0,  0, 16, 17, 24,  5, 25,  2,  5, 22,  6, 10, 14],\n",
            "        [ 0,  0,  0,  0, 17, 23, 13,  4, 13, 16, 22,  5,  9, 14, 23],\n",
            "        [ 0,  0,  0,  0, 26,  5,  2, 18, 18, 25,  1, 20,  4, 18,  5],\n",
            "        [ 0,  0,  0,  0, 15, 17, 13, 18, 19,  8,  9,  9,  6, 15, 14],\n",
            "        [ 0,  0,  0,  0,  9, 26, 14, 20, 25, 26, 10, 24, 26,  3, 10],\n",
            "        [ 0,  0,  0,  0, 19,  7, 24, 15, 11, 17,  8, 17, 19, 10, 10],\n",
            "        [ 0,  0,  0,  0,  4, 10, 25,  4, 22, 13,  8, 20, 14,  7, 10],\n",
            "        [ 0,  0,  0,  0, 21, 24, 17, 16,  1, 16, 23, 21,  4, 16, 22],\n",
            "        [ 0,  0,  0,  0,  1, 17,  2, 14, 10, 20, 22,  6,  2, 11, 18],\n",
            "        [ 0,  0,  0,  0,  5,  9, 15,  9,  9, 25, 19, 18, 11, 20, 15],\n",
            "        [ 0,  0,  0,  0, 15,  3, 23,  6, 16, 13, 25, 13, 11, 13, 25],\n",
            "        [ 0,  0,  0,  0, 14, 17, 19, 25,  5,  5, 22,  9, 20,  1,  3],\n",
            "        [ 0,  0,  0,  0,  5, 24,  7,  7, 15,  5, 18,  7, 25, 15,  7],\n",
            "        [ 0,  0,  0,  0, 25,  4, 15,  7,  8, 17, 12, 12,  8,  8,  2],\n",
            "        [ 0,  0,  0,  0, 15,  8,  3, 10, 12, 15,  8, 18,  6,  3, 20],\n",
            "        [ 0,  0,  0,  0, 23, 12,  2,  3, 10, 13, 25, 13,  1,  4,  1],\n",
            "        [ 0,  0,  0,  0, 14, 11, 18,  5,  6, 14,  6, 14, 12, 21, 17],\n",
            "        [ 0,  0,  0,  0, 22, 17, 17, 14,  2, 19, 21,  2, 18,  4,  9],\n",
            "        [ 0,  0,  0,  0,  7,  8, 23,  2,  1, 11, 25, 20, 11,  2, 26],\n",
            "        [ 0,  0,  0,  0,  5, 22, 24,  3,  9, 10,  1,  1, 14, 22,  1],\n",
            "        [ 0,  0,  0,  0, 25, 25, 20, 14, 18, 19, 14,  9,  7,  5,  2],\n",
            "        [ 0,  0,  0,  0, 19, 22, 18, 15,  9, 24, 22,  2, 24, 11,  8],\n",
            "        [ 0,  0,  0,  0,  6, 18,  5, 25, 21, 21, 23, 13, 23,  9,  6],\n",
            "        [ 0,  0,  0,  0, 26, 20, 15, 17, 10,  8, 16,  3, 21, 26,  6],\n",
            "        [ 0,  0,  0,  0, 19, 26, 13,  2, 22, 20, 26,  4,  1, 18,  2],\n",
            "        [ 0,  0,  0,  0,  5,  3,  6, 11, 25, 26, 24, 22,  1, 18, 12],\n",
            "        [ 0,  0,  0,  0,  7,  6, 12, 26,  2, 13, 11, 16, 17, 25,  4],\n",
            "        [ 0,  0,  0,  0, 22, 16, 15, 21,  2,  3,  2, 23, 22, 22, 17],\n",
            "        [ 0,  0,  0,  0, 15, 19, 14, 26, 25, 14, 16, 10,  8, 25,  1],\n",
            "        [ 0,  0,  0,  0,  2, 12, 11, 21,  3, 22, 12, 20,  2, 12, 26]],\n",
            "       device='cuda:0')\n",
            "TARGET:\n",
            "tensor([[ 0,  0,  0,  0, 10, 14,  8, 10,  9, 26,  1, 21, 11, 26, 15],\n",
            "        [ 0,  0,  0,  0, 24, 11,  9, 26, 24, 10,  6, 17, 19, 11, 15],\n",
            "        [ 0,  0,  0,  0, 18, 24, 12, 21, 20, 22,  8,  5,  6, 15,  7],\n",
            "        [ 0,  0,  0,  0,  3, 11, 23, 22,  4,  4,  5, 20,  5, 22, 20],\n",
            "        [ 0,  0,  0,  0,  1, 21, 13,  9,  6, 24,  4,  2, 11, 15, 22],\n",
            "        [ 0,  0,  0,  0, 19, 20, 21,  7, 10, 17,  5, 23,  5, 19, 12],\n",
            "        [ 0,  0,  0,  0, 19,  6, 24,  9,  4,  9, 20,  4, 12, 14, 10],\n",
            "        [ 0,  0,  0,  0,  3, 18, 18, 10,  3,  5, 11, 14, 18, 20, 17],\n",
            "        [ 0,  0,  0,  0,  1, 12, 18, 22, 21,  3, 20, 15,  7, 15, 18],\n",
            "        [ 0,  0,  0,  0, 23, 17, 18,  8,  3, 14, 18,  8, 15, 26,  6],\n",
            "        [ 0,  0,  0,  0, 24, 20, 22,  1, 16, 15,  3,  1, 16, 17,  4],\n",
            "        [ 0,  0,  0,  0, 16, 18, 21, 24, 19, 17, 14, 11, 21, 13, 16],\n",
            "        [ 0,  0,  0,  0, 16, 20, 23, 19, 24,  1,  3,  7, 20, 19, 13],\n",
            "        [ 0,  0,  0,  0, 10, 10, 22, 26, 17,  2, 10, 12, 23,  4,  6],\n",
            "        [ 0,  0,  0,  0, 19,  8, 26, 14, 24, 13, 17, 18, 24, 20,  6],\n",
            "        [ 0,  0,  0,  0, 23, 15, 26, 25,  9, 23,  5, 22, 13,  7, 20],\n",
            "        [ 0,  0,  0,  0, 23,  6, 15, 21, 17,  1,  8,  6, 20, 25, 22],\n",
            "        [ 0,  0,  0,  0, 22,  6,  1, 22, 24, 25, 11, 14,  9, 19, 21],\n",
            "        [ 0,  0,  0,  0, 17, 24, 19,  1,  6, 10, 23, 11,  2, 13,  7],\n",
            "        [ 0,  0,  0,  0,  5,  5, 23, 11, 17,  2,  3, 19, 22,  8, 14],\n",
            "        [ 0,  0,  0,  0, 16, 17, 24,  5, 25,  2,  5, 22,  6, 10, 14],\n",
            "        [ 0,  0,  0,  0, 17, 23, 13,  4, 13, 16, 22,  5,  9, 14, 23],\n",
            "        [ 0,  0,  0,  0, 26,  5,  2, 18, 18, 25,  1, 20,  4, 18,  5],\n",
            "        [ 0,  0,  0,  0, 15, 17, 13, 18, 19,  8,  9,  9,  6, 15, 14],\n",
            "        [ 0,  0,  0,  0,  9, 26, 14, 20, 25, 26, 10, 24, 26,  3, 10],\n",
            "        [ 0,  0,  0,  0, 19,  7, 24, 15, 11, 17,  8, 17, 19, 10, 10],\n",
            "        [ 0,  0,  0,  0,  4, 10, 25,  4, 22, 13,  8, 20, 14,  7, 10],\n",
            "        [ 0,  0,  0,  0, 21, 24, 17, 16,  1, 16, 23, 21,  4, 16, 22],\n",
            "        [ 0,  0,  0,  0,  1, 17,  2, 14, 10, 20, 22,  6,  2, 11, 18],\n",
            "        [ 0,  0,  0,  0,  5,  9, 15,  9,  9, 25, 19, 18, 11, 20, 15],\n",
            "        [ 0,  0,  0,  0, 15,  3, 23,  6, 16, 13, 25, 13, 11, 13, 25],\n",
            "        [ 0,  0,  0,  0, 14, 17, 19, 25,  5,  5, 22,  9, 20,  1,  3],\n",
            "        [ 0,  0,  0,  0,  5, 24,  7,  7, 15,  5, 18,  7, 25, 15,  7],\n",
            "        [ 0,  0,  0,  0, 25,  4, 15,  7,  8, 17, 12, 12,  8,  8,  2],\n",
            "        [ 0,  0,  0,  0, 15,  8,  3, 10, 12, 15,  8, 18,  6,  3, 20],\n",
            "        [ 0,  0,  0,  0, 23, 12,  2,  3, 10, 13, 25, 13,  1,  4,  1],\n",
            "        [ 0,  0,  0,  0, 14, 11, 18,  5,  6, 14,  6, 14, 12, 21, 17],\n",
            "        [ 0,  0,  0,  0, 22, 17, 17, 14,  2, 19, 21,  2, 18,  4,  9],\n",
            "        [ 0,  0,  0,  0,  7,  8, 23,  2,  1, 11, 25, 20, 11,  2, 26],\n",
            "        [ 0,  0,  0,  0,  5, 22, 24,  3,  9, 10,  1,  1, 14, 22,  1],\n",
            "        [ 0,  0,  0,  0, 25, 25, 20, 14, 18, 19, 14,  9,  7,  5,  2],\n",
            "        [ 0,  0,  0,  0, 19, 22, 18, 15,  9, 24, 22,  2, 24, 11,  8],\n",
            "        [ 0,  0,  0,  0,  6, 18,  5, 25, 21, 21, 23, 13, 23,  9,  6],\n",
            "        [ 0,  0,  0,  0, 26, 20, 15, 17, 10,  8, 16,  3, 21, 26,  6],\n",
            "        [ 0,  0,  0,  0, 19, 26, 13,  2, 22, 20, 26,  4,  1, 18,  2],\n",
            "        [ 0,  0,  0,  0,  5,  3,  6, 11, 25, 26, 24, 22,  1, 18, 12],\n",
            "        [ 0,  0,  0,  0,  7,  6, 12, 26,  2, 13, 11, 16, 17, 25,  4],\n",
            "        [ 0,  0,  0,  0, 22, 16, 15, 21,  2,  3,  2, 23, 22, 22, 17],\n",
            "        [ 0,  0,  0,  0, 15, 19, 14, 26, 25, 14, 16, 10,  8, 25,  1],\n",
            "        [ 0,  0,  0,  0,  2, 12, 11, 21,  3, 22, 12, 20,  2, 12, 26]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Train Epoch: 2/10, loss: 0.001, accuracy 99.9%\n",
            "Train Epoch: 3/10, loss: 0.081, accuracy 100.0%\n",
            "Train Epoch: 4/10, loss: 0.000, accuracy 100.0%\n",
            "Train Epoch: 5/10, loss: 0.000, accuracy 100.0%\n",
            "Train Epoch: 6/10, loss: 0.000, accuracy 100.0%\n",
            "Train Epoch: 7/10, loss: 0.000, accuracy 100.0%\n",
            "PREDICTION:\n",
            "tensor([[ 0,  0,  0,  0, 19, 10,  7, 10, 13, 23,  9,  5, 10, 13,  6],\n",
            "        [ 0,  0,  0,  0, 21, 11, 12, 14,  5, 17, 22,  3,  6, 16, 24],\n",
            "        [ 0,  0,  0,  0,  4, 23, 14, 15, 16,  6, 22, 23, 25, 13, 12],\n",
            "        [ 0,  0,  0,  0,  5, 23,  2, 20, 21, 15,  9, 23, 14,  4, 12],\n",
            "        [ 0,  0,  0,  0, 16,  8, 26, 25, 11,  9, 15, 10,  4, 24,  7],\n",
            "        [ 0,  0,  0,  0, 12,  3, 23,  3,  3,  3,  2, 23,  6,  3,  1],\n",
            "        [ 0,  0,  0,  0, 18, 25,  7,  2,  9,  3,  2, 10,  7, 23,  4],\n",
            "        [ 0,  0,  0,  0, 15, 15, 23, 26, 25, 15,  5, 22, 15, 15,  2],\n",
            "        [ 0,  0,  0,  0,  3, 10,  8, 14, 14, 13,  5, 11,  4,  3,  8],\n",
            "        [ 0,  0,  0,  0, 17, 20,  1,  9,  7, 12,  5,  9,  3, 24, 13],\n",
            "        [ 0,  0,  0,  0, 22, 25, 11, 24,  9,  9, 11, 22, 19, 19, 21],\n",
            "        [ 0,  0,  0,  0, 18, 17,  2, 14,  5, 15, 19,  7,  4,  8, 13],\n",
            "        [ 0,  0,  0,  0, 17, 19,  8, 16, 17, 26, 11, 21, 16, 10, 10],\n",
            "        [ 0,  0,  0,  0, 19,  4, 10, 20,  7, 22, 26, 19, 24, 18, 26],\n",
            "        [ 0,  0,  0,  0,  4, 20, 14,  6, 25,  5,  3, 24, 17, 21,  7],\n",
            "        [ 0,  0,  0,  0, 17, 18, 13,  4, 12, 16, 18,  7, 18, 24, 10],\n",
            "        [ 0,  0,  0,  0, 12,  2, 20, 24, 19, 25, 12, 23, 12, 24, 19],\n",
            "        [ 0,  0,  0,  0, 24,  7, 12, 26, 23,  3, 20, 16, 15,  7, 20],\n",
            "        [ 0,  0,  0,  0, 12,  5,  8,  4, 10, 20, 10, 19, 23,  8, 17],\n",
            "        [ 0,  0,  0,  0,  6, 19, 10,  9, 18, 20, 11, 15, 26,  3,  8],\n",
            "        [ 0,  0,  0,  0, 24, 22, 11, 24,  1, 18,  8, 21, 21, 26, 11],\n",
            "        [ 0,  0,  0,  0,  9, 12, 21,  1,  9,  7,  7,  1, 26,  6,  3],\n",
            "        [ 0,  0,  0,  0, 10, 24, 21, 12, 11, 23, 13, 11,  4, 12, 16],\n",
            "        [ 0,  0,  0,  0, 25,  2,  6, 13, 11, 21, 14, 12,  1, 18, 21],\n",
            "        [ 0,  0,  0,  0, 20, 14, 22, 13, 21,  1,  2, 12, 19, 25, 11],\n",
            "        [ 0,  0,  0,  0,  7, 14, 17, 15,  5,  5, 11, 11,  7, 22,  1],\n",
            "        [ 0,  0,  0,  0,  1,  5, 19, 17,  2,  9, 23, 11, 24,  9, 15],\n",
            "        [ 0,  0,  0,  0,  6,  1, 12, 13,  4, 16, 17, 21, 14,  5, 26],\n",
            "        [ 0,  0,  0,  0, 16, 16, 10, 11,  7,  1,  1, 24,  8,  8,  6],\n",
            "        [ 0,  0,  0,  0, 16, 23, 19, 23,  4, 21, 26, 13, 23,  4, 17],\n",
            "        [ 0,  0,  0,  0,  7, 25, 18, 11,  4,  8,  7, 17,  7, 19,  1],\n",
            "        [ 0,  0,  0,  0, 20,  8, 15, 20, 12, 16,  7, 17, 13, 21, 11],\n",
            "        [ 0,  0,  0,  0,  8, 21, 16, 14, 19, 22, 21, 18, 17, 22, 15],\n",
            "        [ 0,  0,  0,  0, 17, 22,  2,  9, 18, 15, 15, 19, 25, 16, 25],\n",
            "        [ 0,  0,  0,  0, 26,  8,  9, 24,  7,  1, 10, 10, 15, 26, 19],\n",
            "        [ 0,  0,  0,  0,  5, 22,  5,  7, 10, 25, 21, 22, 25, 13, 11],\n",
            "        [ 0,  0,  0,  0, 22,  9,  6, 25,  2, 25, 21, 25, 26,  6, 23],\n",
            "        [ 0,  0,  0,  0,  2, 16, 24, 10,  9, 19, 15, 23, 18,  5, 26],\n",
            "        [ 0,  0,  0,  0, 16, 13, 17, 22,  9, 10, 11, 14, 25, 13,  6],\n",
            "        [ 0,  0,  0,  0,  5,  2, 17, 14, 18, 22, 17, 14,  9, 15, 23],\n",
            "        [ 0,  0,  0,  0,  6,  7, 10, 16,  2, 19,  5,  3, 21, 24, 25],\n",
            "        [ 0,  0,  0,  0, 25, 18,  4,  9, 13, 24,  8, 18,  6,  8,  4],\n",
            "        [ 0,  0,  0,  0,  2,  1,  2,  3, 23, 11,  6,  7, 14, 20, 20],\n",
            "        [ 0,  0,  0,  0, 14,  4,  4,  8, 24,  3, 20, 25,  3, 25, 15],\n",
            "        [ 0,  0,  0,  0,  5, 22,  4, 26,  3, 18, 18, 24, 15, 21,  3],\n",
            "        [ 0,  0,  0,  0,  2, 21,  4,  9, 13, 18, 11, 18, 11,  9,  2],\n",
            "        [ 0,  0,  0,  0,  7, 10,  5, 25, 18,  5, 26,  5, 26,  1, 24],\n",
            "        [ 0,  0,  0,  0, 11,  3,  2,  9, 10, 16,  8,  8, 15, 10, 18],\n",
            "        [ 0,  0,  0,  0,  7, 15, 17, 11, 14, 13,  7,  4, 14, 10, 26],\n",
            "        [ 0,  0,  0,  0, 11, 21, 26,  6, 20,  6,  4, 24,  3, 15,  3]],\n",
            "       device='cuda:0')\n",
            "TARGET:\n",
            "tensor([[ 0,  0,  0,  0, 19, 10,  7, 10, 13, 23,  9,  5, 10, 13,  6],\n",
            "        [ 0,  0,  0,  0, 21, 11, 12, 14,  5, 17, 22,  3,  6, 16, 24],\n",
            "        [ 0,  0,  0,  0,  4, 23, 14, 15, 16,  6, 22, 23, 25, 13, 12],\n",
            "        [ 0,  0,  0,  0,  5, 23,  2, 20, 21, 15,  9, 23, 14,  4, 12],\n",
            "        [ 0,  0,  0,  0, 16,  8, 26, 25, 11,  9, 15, 10,  4, 24,  7],\n",
            "        [ 0,  0,  0,  0, 12,  3, 23,  3,  3,  3,  2, 23,  6,  3,  1],\n",
            "        [ 0,  0,  0,  0, 18, 25,  7,  2,  9,  3,  2, 10,  7, 23,  4],\n",
            "        [ 0,  0,  0,  0, 15, 15, 23, 26, 25, 15,  5, 22, 15, 15,  2],\n",
            "        [ 0,  0,  0,  0,  3, 10,  8, 14, 14, 13,  5, 11,  4,  3,  8],\n",
            "        [ 0,  0,  0,  0, 17, 20,  1,  9,  7, 12,  5,  9,  3, 24, 13],\n",
            "        [ 0,  0,  0,  0, 22, 25, 11, 24,  9,  9, 11, 22, 19, 19, 21],\n",
            "        [ 0,  0,  0,  0, 18, 17,  2, 14,  5, 15, 19,  7,  4,  8, 13],\n",
            "        [ 0,  0,  0,  0, 17, 19,  8, 16, 17, 26, 11, 21, 16, 10, 10],\n",
            "        [ 0,  0,  0,  0, 19,  4, 10, 20,  7, 22, 26, 19, 24, 18, 26],\n",
            "        [ 0,  0,  0,  0,  4, 20, 14,  6, 25,  5,  3, 24, 17, 21,  7],\n",
            "        [ 0,  0,  0,  0, 17, 18, 13,  4, 12, 16, 18,  7, 18, 24, 10],\n",
            "        [ 0,  0,  0,  0, 12,  2, 20, 24, 19, 25, 12, 23, 12, 24, 19],\n",
            "        [ 0,  0,  0,  0, 24,  7, 12, 26, 23,  3, 20, 16, 15,  7, 20],\n",
            "        [ 0,  0,  0,  0, 12,  5,  8,  4, 10, 20, 10, 19, 23,  8, 17],\n",
            "        [ 0,  0,  0,  0,  6, 19, 10,  9, 18, 20, 11, 15, 26,  3,  8],\n",
            "        [ 0,  0,  0,  0, 24, 22, 11, 24,  1, 18,  8, 21, 21, 26, 11],\n",
            "        [ 0,  0,  0,  0,  9, 12, 21,  1,  9,  7,  7,  1, 26,  6,  3],\n",
            "        [ 0,  0,  0,  0, 10, 24, 21, 12, 11, 23, 13, 11,  4, 12, 16],\n",
            "        [ 0,  0,  0,  0, 25,  2,  6, 13, 11, 21, 14, 12,  1, 18, 21],\n",
            "        [ 0,  0,  0,  0, 20, 14, 22, 13, 21,  1,  2, 12, 19, 25, 11],\n",
            "        [ 0,  0,  0,  0,  7, 14, 17, 15,  5,  5, 11, 11,  7, 22,  1],\n",
            "        [ 0,  0,  0,  0,  1,  5, 19, 17,  2,  9, 23, 11, 24,  9, 15],\n",
            "        [ 0,  0,  0,  0,  6,  1, 12, 13,  4, 16, 17, 21, 14,  5, 26],\n",
            "        [ 0,  0,  0,  0, 16, 16, 10, 11,  7,  1,  1, 24,  8,  8,  6],\n",
            "        [ 0,  0,  0,  0, 16, 23, 19, 23,  4, 21, 26, 13, 23,  4, 17],\n",
            "        [ 0,  0,  0,  0,  7, 25, 18, 11,  4,  8,  7, 17,  7, 19,  1],\n",
            "        [ 0,  0,  0,  0, 20,  8, 15, 20, 12, 16,  7, 17, 13, 21, 11],\n",
            "        [ 0,  0,  0,  0,  8, 21, 16, 14, 19, 22, 21, 18, 17, 22, 15],\n",
            "        [ 0,  0,  0,  0, 17, 22,  2,  9, 18, 15, 15, 19, 25, 16, 25],\n",
            "        [ 0,  0,  0,  0, 26,  8,  9, 24,  7,  1, 10, 10, 15, 26, 19],\n",
            "        [ 0,  0,  0,  0,  5, 22,  5,  7, 10, 25, 21, 22, 25, 13, 11],\n",
            "        [ 0,  0,  0,  0, 22,  9,  6, 25,  2, 25, 21, 25, 26,  6, 23],\n",
            "        [ 0,  0,  0,  0,  2, 16, 24, 10,  9, 19, 15, 23, 18,  5, 26],\n",
            "        [ 0,  0,  0,  0, 16, 13, 17, 22,  9, 10, 11, 14, 25, 13,  6],\n",
            "        [ 0,  0,  0,  0,  5,  2, 17, 14, 18, 22, 17, 14,  9, 15, 23],\n",
            "        [ 0,  0,  0,  0,  6,  7, 10, 16,  2, 19,  5,  3, 21, 24, 25],\n",
            "        [ 0,  0,  0,  0, 25, 18,  4,  9, 13, 24,  8, 18,  6,  8,  4],\n",
            "        [ 0,  0,  0,  0,  2,  1,  2,  3, 23, 11,  6,  7, 14, 20, 20],\n",
            "        [ 0,  0,  0,  0, 14,  4,  4,  8, 24,  3, 20, 25,  3, 25, 15],\n",
            "        [ 0,  0,  0,  0,  5, 22,  4, 26,  3, 18, 18, 24, 15, 21,  3],\n",
            "        [ 0,  0,  0,  0,  2, 21,  4,  9, 13, 18, 11, 18, 11,  9,  2],\n",
            "        [ 0,  0,  0,  0,  7, 10,  5, 25, 18,  5, 26,  5, 26,  1, 24],\n",
            "        [ 0,  0,  0,  0, 11,  3,  2,  9, 10, 16,  8,  8, 15, 10, 18],\n",
            "        [ 0,  0,  0,  0,  7, 15, 17, 11, 14, 13,  7,  4, 14, 10, 26],\n",
            "        [ 0,  0,  0,  0, 11, 21, 26,  6, 20,  6,  4, 24,  3, 15,  3]],\n",
            "       device='cuda:0')\n",
            "\n",
            "Train Epoch: 8/10, loss: 0.000, accuracy 100.0%\n",
            "Train Epoch: 9/10, loss: 0.000, accuracy 100.0%\n",
            "Train Epoch: 10/10, loss: 0.000, accuracy 100.0%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# TODO: initialize and train your model here.\n",
        "end_time = time.time()\n",
        "duration = end_time - start_time\n",
        "\n",
        "# call training function\n",
        "model.to(device)\n",
        "n_epochs = 10\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    correct, loss = train(epoch)\n",
        "    train_accuracy = float(correct)*100\n",
        "    print(f'Train Epoch: {epoch}/{n_epochs}, loss: {loss:.3f}, accuracy {train_accuracy:.1f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = test_model(model)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Training time:\", round(duration/60), \"minutes\")\n",
        "\n",
        "assert duration < 600, 'execution took f{duration:.2f} seconds, which longer than 10 mins'\n",
        "assert accuracy > 0.99, f'accuracy is too low, got {accuracy}, need 0.99'\n",
        "print('tests passed')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM_TuQKSXZjc",
        "outputId": "167dee09-07c1-42b3-ee94-8dfa6e01d1b4"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Training time: 0 minutes\n",
            "tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkhQFStDpbbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg9ysAVfpbbt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sB0EVNBtDhpN"
      },
      "source": [
        "## Variable delay model\n",
        "\n",
        "Now, to make this more complicated, we want to have varialbe delay. So, now, the goal is to transform a sequence of pairs (character, delay) into a character sequence with given delay. Delay stays constant within one sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3i_iwX_AEOCH"
      },
      "source": [
        "### Dataset\n",
        "As before, we first implement the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4G5b8kuEUEd"
      },
      "outputs": [],
      "source": [
        "class VariableDelayEchoDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "  def __init__(self, max_delay=8, seq_length=20, size=1000):\n",
        "    self.max_delay = max_delay\n",
        "    self.seq_length = seq_length\n",
        "    self.size = size\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.size\n",
        "\n",
        "  def __iter__(self):\n",
        "    for _ in range(self.size):\n",
        "      seq = torch.tensor([random.choice(range(1, N + 1)) for i in range(self.seq_length)], dtype=torch.int64)\n",
        "      delay = random.randint(0, self.max_delay)\n",
        "      result = torch.cat((torch.zeros(delay), seq[:self.seq_length - delay])).type(torch.int64)\n",
        "      yield seq, delay, result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTRVOND3HEJZ"
      },
      "source": [
        "### Model\n",
        "\n",
        "And the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYolFIB8Hg0U"
      },
      "outputs": [],
      "source": [
        "class VariableDelayGRUMemory(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size, max_delay):\n",
        "    super().__init__()\n",
        "    #TODO\n",
        "\n",
        "  def forward(self, x, delays):\n",
        "    # inputs:\n",
        "    # x - tensor of shape (batch size, seq length, N + 1)\n",
        "    # delays - tensor of shape (batch size)\n",
        "    # returns:\n",
        "    # logits (scores for softmax) of shape (batch size, seq_length, N + 1)\n",
        "\n",
        "    # TODO\n",
        "    pass\n",
        "\n",
        "  @torch.no_grad()\n",
        "  def test_run(self, s, delay):\n",
        "    # This function accepts one string s containing lowercase characters a-z,\n",
        "    # and a delay - the desired output delay.\n",
        "    # You need to map those characters to one-hot encodings,\n",
        "    # then get the result from your network, and then convert the output\n",
        "    # back to a string of the same length, with 0 mapped to ' ',\n",
        "    # and 1-26 mapped to a-z.\n",
        "\n",
        "    # TODO\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riu3qHWgKjsx"
      },
      "source": [
        "### Train\n",
        "\n",
        "As before, you're free to do what you want, as long as training finishes within 10 minutes and accuracy is above 0.99 for delays between 0 and 8."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FZHojnGO3aw"
      },
      "outputs": [],
      "source": [
        "def test_variable_delay_model(model, seq_length=20):\n",
        "  \"\"\"\n",
        "  This is the test function that runs 100 different strings through your model,\n",
        "  and checks the error rate.\n",
        "  \"\"\"\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for i in range(500):\n",
        "    s = ''.join([random.choice(string.ascii_lowercase) for i in range(seq_length)])\n",
        "    d = random.randint(0, model.max_delay)\n",
        "    result = model.test_run(s, d)\n",
        "    if d > 0:\n",
        "      z = zip(s[:-d], result[d:])\n",
        "    else:\n",
        "      z = zip(s, result)\n",
        "    for c1, c2 in z:\n",
        "      correct += int(c1 == c2)\n",
        "    total += len(s) - d\n",
        "\n",
        "  return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJ18Ef6vKi4s"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "MAX_DELAY = 8\n",
        "SEQ_LENGTH = 20\n",
        "\n",
        "# TODO: implement model training here.\n",
        "model = None\n",
        "\n",
        "end_time = time.time()\n",
        "assert end_time - start_time < 600, 'executing took longer than 10 mins'\n",
        "assert test_variable_delay_model(model) > 0.99, 'accuracy is too low'\n",
        "print('tests passed')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "environment": {
      "kernel": "python3",
      "name": "pytorch-gpu.1-12.m98",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m98"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}